{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import torch\n",
    "from transformers import MllamaForConditionalGeneration, MllamaProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MllamaForConditionalGeneration.from_pretrained(\n",
    "    'Bllossom/llama-3.2-Korean-Bllossom-AICA-5B',\n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map='auto'\n",
    ")\n",
    "processor = MllamaProcessor.from_pretrained('Bllossom/llama-3.2-Korean-Bllossom-AICA-5B')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(mode, text):\n",
    "    if mode == \"summary\":\n",
    "        prompt = \"다음 텍스트를 요약해줘: \"\n",
    "    elif mode == \"quiz\":\n",
    "        prompt = \"다음 텍스트로 문제와 정답을 1개만 만들어줘: \"\n",
    "    \n",
    "    messages = [{'role': 'user',\n",
    "                 'content': [{'type': 'text',\n",
    "                              'text': prompt+text}]}]\n",
    "\n",
    "    input_text = processor.apply_chat_template(messages,\n",
    "                                               tokenize=False,\n",
    "                                               add_generation_prompt=True)\n",
    "\n",
    "    inputs = processor(text=input_text,\n",
    "                       add_special_tokens=False,\n",
    "                       return_tensors=\"pt\").to(model.device)\n",
    "\n",
    "    output = model.generate(**inputs,\n",
    "                            max_new_tokens=256,\n",
    "                            temperature=0.1,\n",
    "                            eos_token_id=processor.tokenizer.convert_tokens_to_ids('<|eot_id|>'),\n",
    "                            use_cache=False)\n",
    "    \n",
    "    output_text = processor.decode(output[0])\n",
    "\n",
    "    match = re.search(r'<\\|start_header_id\\|>assistant<\\|end_header_id\\|>(.*?)<\\|eot_id\\|>',\n",
    "                      output_text,\n",
    "                      re.DOTALL)\n",
    "    \n",
    "    return match.group(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "엔비디아가 차세대 게이밍 GPU(그래픽처리장치) '지포스 RTX 50시리즈'를 내놓으며 PC용 AI칩 시장을 겨냥한다. 올해 초 미국 라스베이거스서 개최된 CES 2025에서 선보인 바 있는 RTX 50 시리즈는 개인용 AI PC 시장을 바꿔놓을 게임 체인저로 지목되면서 향후 인텔, 퀄컴, AMD 등과의 치열한 각축전이 예상되고 있다. 20일 엔비디아는 서울 코엑스에서 'RTX AI PC 데이'를 열고 새로운 아키텍처 '블랙웰'이 탑재된 '지포스 RTX 50 시리즈'를 발표했다. 이는 RTX는 엔비디아가 만든 GPU(그래픽처리장치)인데 이번에 새롭게 나온 50 시리즈(5090, 5080, 5070TI, 5070)등은 이전 세대보다 강화된 AI(인공지능) 기술과 낮아진 가격을 자랑한다. 이중에서도 5090 제품의 경우 최고급 PC에 주로 사용되며 게이밍, 그래픽 연산 등에 주로 사용된다. 게이머 뿐 아니라 개발자, 크리에이터 등을 위한 최고 사양을 자랑한다. RTX 5090의 경우 초당 데이터 전송량이 초당 1.8TB(테라바이트)로, 이전 모델인 RTX 4090보다 두 배 향상됐다. 성능은 높아졌으나 배터리 효율은 더욱 개선됐다는 것이 엔비디아 측의 설명이다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = generate(\"summary\", text)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz = generate(\"quiz\", summary)\n",
    "print(quiz)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
