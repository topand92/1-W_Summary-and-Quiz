{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd8bcf833c824e5da63d31dcd8f365b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LlamaForCausalLM(\n",
       "  (model): LlamaModel(\n",
       "    (embed_tokens): Embedding(128256, 3072)\n",
       "    (layers): ModuleList(\n",
       "      (0-27): 28 x LlamaDecoderLayer(\n",
       "        (self_attn): LlamaAttention(\n",
       "          (q_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "          (k_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (v_proj): Linear(in_features=3072, out_features=1024, bias=False)\n",
       "          (o_proj): Linear(in_features=3072, out_features=3072, bias=False)\n",
       "        )\n",
       "        (mlp): LlamaMLP(\n",
       "          (gate_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (up_proj): Linear(in_features=3072, out_features=8192, bias=False)\n",
       "          (down_proj): Linear(in_features=8192, out_features=3072, bias=False)\n",
       "          (act_fn): SiLU()\n",
       "        )\n",
       "        (input_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "        (post_attention_layernorm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "      )\n",
       "    )\n",
       "    (norm): LlamaRMSNorm((3072,), eps=1e-05)\n",
       "    (rotary_emb): LlamaRotaryEmbedding()\n",
       "  )\n",
       "  (lm_head): Linear(in_features=3072, out_features=128256, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 및 토크나이저 로드\n",
    "model_path = \"./model\" # 로컬 모델 경로\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path)\n",
    "\n",
    "# GPU 사용 설정\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요약할 텍스트\n",
    "text = \"\"\"\n",
    "뇌-컴퓨터 인터페이스(Brain-Computer Interface, BCI) 기술이 급격히 발전하면서 신경 장애를 가진 환자들에게 새로운 삶의 가능성을 열고 있다.\n",
    "단순히 운동 기능을 복원하는 수준을 넘어서 일상 생활이나 비디오 게임과 같은 여가 활동을 가능하게 하는 데까지 도달했다.\n",
    "미국 미시간대 연구진은 심각한 운동 장애를 겪는 환자들이 비디오 게임과 같은 여가 활동을 할 수 있도록 돕는 BCI 기술을 개발했다고 밝혔다.\n",
    "연구 결과는 국제 학술지 ‘네이처 메디신(Nature Medicine)’에 21일 공개됐다.\n",
    "BCI 기술은 뇌와 컴퓨터를 연결해 신체 기능을 복원하거나, 인간의 의도를 외부 기기로 전달하는 기술이다.\n",
    "기존 BCI 기술은 마비 환자의 운동 기능 일부를 복원하는 데 사용돼 왔으나, 손가락 움직임과 같은 정교한 동작을 재현하는 데는 한계가 있었다.\n",
    "따라서 타이핑이나 악기 연주, 게임 컨트롤러 조작과 같은 활동을 구현하기에는 어려웠다.\n",
    "연구진은 척수 손상으로 사지마비를 앓는 환자의 뇌에 전극을 이식해 손 움직임과 관련된 신경 신호를 기록했다.\n",
    "환자가 가상 손의 움직임을 관찰할 때 뇌에서 나오는 신경 데이터를 머신러닝 알고리즘으로 분석해 특정 손가락 움직임과 연관된 신호를 식별했다.\n",
    "이를 기반으로 뇌에 전극을 이식한 환자가 손가락을 움직이는 것을 상상하는 것만으로 비디오 게임 속 가상 드론을 조종할 수 있게 했다.\n",
    "환자는 가상 드론의 속도와 방향을 자유롭게 조절하며 여러 장애물을 통과하는 비디오 게임을 성공적으로 수행했다.\n",
    "\"\"\"\n",
    "\n",
    "# 프롬프트 생성 (요약 지시)\n",
    "summary_prompt = f\"다음 글을 간결하게 요약하세요:\\n{text}\\n요약:\"\n",
    "\n",
    "# 입력 텍스트 토크나이즈\n",
    "inputs = tokenizer(summary_prompt, return_tensors=\"pt\", max_length=2048, truncation=True)\n",
    "inputs = {key: value.to(device) for key, value in inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n"
     ]
    }
   ],
   "source": [
    "# 요약 생성\n",
    "output_ids = model.generate(\n",
    "    inputs[\"input_ids\"],\n",
    "    max_new_tokens=150,     # 요약 최대 길이\n",
    "    temperature=0.7,        # 창의성 조절\n",
    "    top_p=0.9,              # 확률 분포 컷오프\n",
    "    repetition_penalty=1.2, # 반복 방지\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "요약 결과: 다음 글을 간결하게 요약하세요:\n",
      "\n",
      "뇌-컴퓨터 인터페이스(Brain-Computer Interface, BCI) 기술이 급격히 발전하면서 신경 장애를 가진 환자들에게 새로운 삶의 가능성을 열고 있다.\n",
      "단순히 운동 기능을 복원하는 수준을 넘어서 일상 생활이나 비디오 게임과 같은 여가 활동을 가능하게 하는 데까지 도달했다.\n",
      "미국 미시간대 연구진은 심각한 운동 장애를 겪는 환자들이 비디오 게임과 같은 여가 활동을 할 수 있도록 돕는 BCI 기술을 개발했다고 밝혔다.\n",
      "연구 결과는 국제 학술지 ‘네이처 메디신(Nature Medicine)’에 21일 공개됐다.\n",
      "BCI 기술은 뇌와 컴퓨터를 연결해 신체 기능을 복원하거나, 인간의 의도를 외부 기기로 전달하는 기술이다.\n",
      "기존 BCI 기술은 마비 환자의 운동 기능 일부를 복원하는 데 사용돼 왔으나, 손가락 움직임과 같은 정교한 동작을 재현하는 데는 한계가 있었다.\n",
      "따라서 타이핑이나 악기 연주, 게임 컨트롤러 조작과 같은 활동을 구현하기에는 어려웠다.\n",
      "연구진은 척수 손상으로 사지마비를 앓는 환자의 뇌에 전극을 이식해 손 움직임과 관련된 신경 신호를 기록했다.\n",
      "환자가 가상 손의 움직임을 관찰할 때 뇌에서 나오는 신경 데이터를 머신러닝 알고리즘으로 분석해 특정 손가락 움직임과 연관된 신호를 식별했다.\n",
      "이를 기반으로 뇌에 전극을 이식한 환자가 손가락을 움직이는 것을 상상하는 것만으로 비디오 게임 속 가상 드론을 조종할 수 있게 했다.\n",
      "환자는 가상 드론의 속도와 방향을 자유롭게 조절하며 여러 장애물을 통과하는 비디오 게임을 성공적으로 수행했다.\n",
      "\n",
      "요약: BCI 기술을 통해 심각한 운동 장애를 가진 환자가 비디오 게임 등을 즐길 수 있는 방법을 찾았다. 환자가 뇌로 전송되는 신경 신호를 분석하고 이를 바탕으로 비ideo 게임에 참여할 수 있도록 하여, 이전에는 불가능했던 활동들을 possible로 만들었다. 이는 future에서는 더 많은 사람들에게 새로운 삶의 가능성을 제공할 것으로 예측된다.\n"
     ]
    }
   ],
   "source": [
    "# 결과 디코딩\n",
    "summary_text = tokenizer.decode(output_ids[0], skip_special_tokens=True)\n",
    "print(\"요약 결과:\", summary_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2단계: 요약 텍스트로 퀴즈 생성\n",
    "quiz_prompt = f\"다음 요약 내용을 기반으로 주관식 퀴즈와 정답을 생성하세요:\\n{summary_text}\\n퀴즈:\"\n",
    "quiz_inputs = tokenizer(quiz_prompt, return_tensors=\"pt\", max_length=2048, truncation=True)\n",
    "quiz_inputs = {key: value.to(device) for key, value in quiz_inputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_ids = model.generate(\n",
    "    quiz_inputs[\"input_ids\"],\n",
    "    max_new_tokens=200,\n",
    "    temperature=0.7,\n",
    "    top_p=0.9,\n",
    "    repetition_penalty=1.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_output = tokenizer.decode(quiz_ids[0], skip_special_tokens=True)\n",
    "print(\"\\n생성된 퀴즈 및 정답:\\n\", quiz_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
